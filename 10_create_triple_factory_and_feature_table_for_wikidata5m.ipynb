{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8026f2f-b407-4280-95f0-e909a94cf6f5",
   "metadata": {},
   "source": [
    "# Create Knowledge Graph and Its Features Table for Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb33c186-0a5a-4fcf-9674-e84866b4c2a0",
   "metadata": {},
   "source": [
    "## modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a5c27dd-7e3f-4e21-a610-0f579b375f36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/acg16558pn/kg_20240423/lib/python3.10/site-packages/pykeen/evaluation/evaluator.py:16: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "import spacy\n",
    "import pandas as pd\n",
    "from pykeen.pipeline import pipeline\n",
    "from pykeen.datasets import get_dataset\n",
    "from pykeen.models import TransE, ComplEx, ConvE\n",
    "from pykeen.losses import Loss\n",
    "from pykeen.models.base import Model\n",
    "from pykeen.triples import TriplesFactory\n",
    "from pykeen.triples import TriplesNumericLiteralsFactory\n",
    "from tqdm import tqdm\n",
    "from util.databinder import DataBinder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de99fe1a-00a0-4b18-a2e1-ba181140fd01",
   "metadata": {},
   "source": [
    "## variable, functions, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d93d3b51-eafb-4c6a-9a7d-cf91b60f1428",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_triples(tf:TriplesFactory, ratio:float=0.01) -> TriplesFactory:\n",
    "    num_samples = int(tf.num_triples * ratio)\n",
    "    sampled_indices = np.random.choice(tf.num_triples, size=num_samples, replace=False)\n",
    "    sampled_tf = TriplesFactory.from_labeled_triples(tf.triples[sampled_indices])\n",
    "    return sampled_tf\n",
    "\n",
    "def create_false_triples(tf:TriplesFactory, ratio:float=0.1) -> TriplesFactory:\n",
    "    num_false = int(tf.num_triples * ratio)\n",
    "    false_triples = tf.mapped_triples.clone()\n",
    "    false_indices = np.random.choice(tf.num_triples, num_false)\n",
    "    for i in false_indices:\n",
    "        if np.random.random() < 0.5:  # Replace head\n",
    "            false_triples[i, 0] = np.random.choice(tf.num_entities)\n",
    "        else:  # Replace tail\n",
    "            false_triples[i, 2] = np.random.choice(tf.num_entities)\n",
    "    return TriplesFactory(false_triples, tf.entity_to_id, tf.relation_to_id), false_indices\n",
    "\n",
    "def create_triples_feature_table(tf:TriplesFactory) -> pd.DataFrame:\n",
    "    triples = tf.mapped_triples.numpy()\n",
    "    head_labels = [tf.entity_id_to_label[h] for h in triples[:, 0]]\n",
    "    relation_labels = [tf.relation_id_to_label[r] for r in triples[:, 1]]\n",
    "    tail_labels = [tf.entity_id_to_label[t] for t in triples[:, 2]]\n",
    "    \n",
    "    # Calculate degrees\n",
    "    head_degrees = np.array([np.sum(triples[:, 0] == h) for h in triples[:, 0]])\n",
    "    tail_degrees = np.array([np.sum(triples[:, 2] == t) for t in triples[:, 2]])\n",
    "    \n",
    "    return pd.DataFrame({\n",
    "        'head': head_labels,\n",
    "        'relation': relation_labels,\n",
    "        'tail': tail_labels,\n",
    "        'head_degree': head_degrees,\n",
    "        'tail_degree': tail_degrees,\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a8059d-a7bd-4f08-813e-a0244552ca5b",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2daca6f1-c1cb-46b8-9cdb-77e899ba50be",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_kg = 'Wikidata5M'\n",
    "sampling_ratio = 1e-3\n",
    "f_sr_description = './data/raw/sr_wikidata5m_text.pkl'\n",
    "dir_save = './data/processed/20240616_sampled_wikidata_5m'\n",
    "name_nlp = 'en_core_web_lg'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573d85cd-99fb-4296-9d76-eda7df4c2e4f",
   "metadata": {},
   "source": [
    "## 1. Load knowledge graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee21e272-d159-4bbb-be87-dc13df92a5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = get_dataset(dataset=name_kg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04a00d1d-bf0e-4c97-bfce-68ec066513c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EagerDataset (create_inverse_triples=False)\n",
      "Name        Entities    Relations      Triples\n",
      "----------  ----------  -----------  ---------\n",
      "Training    4594149     822           20614279\n",
      "Testing     4594149     822               4977\n",
      "Validation  4594149     822               4983\n",
      "Total       -           -             20624239\n",
      "Head    Relation    tail\n",
      "------  ----------  --------\n",
      "Q1      P1343       Q602358\n",
      "Q1      P1419       Q1647152\n",
      "Q1      P1552       Q11412\n",
      "Q1      P2184       Q136407\n",
      "Q1      P2670       Q18343\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset.summarize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9874d9f1-4b4c-4fff-a5cd-dd65de8e9b94",
   "metadata": {},
   "source": [
    "Use only training data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1928ebf4-231c-4dca-b83d-e3a5558f4c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_org = dataset.training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7cc2ee1-3803-4827-b0ba-d9048f6cdf06",
   "metadata": {},
   "source": [
    "## 2. Sampling Knowledge Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d346e6a4-5bc6-4283-9290-cd5f8ee6b23c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reconstructing all label-based triples. This is expensive and rarely needed.\n"
     ]
    }
   ],
   "source": [
    "tf = sample_triples(tf_org, ratio=sampling_ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e71714-44e8-4f92-8052-f384786e26f3",
   "metadata": {},
   "source": [
    "## 3. Create TriplesNumericLiteralsFactory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eacae3d2-88dc-4f5f-89eb-f3064904de46",
   "metadata": {},
   "source": [
    "For detail, please see [TriplesNumericLiteralsFactory](https://pykeen.readthedocs.io/en/stable/reference/triples.html#pykeen.triples.TriplesNumericLiteralsFactory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f582eaa9-3ec1-486e-91ea-393db6907dce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 29642/29642 [08:29<00:00, 58.20it/s]\n"
     ]
    }
   ],
   "source": [
    "n_entity = len(tf.entity_id_to_label)\n",
    "\n",
    "nlp = spacy.load(name_nlp)\n",
    "dim_embedding = nlp.vocab.vectors_length\n",
    "\n",
    "numeric_literals = np.zeros((n_entity, dim_embedding))\n",
    "\n",
    "sr_description = pd.read_pickle(f_sr_description)\n",
    "for _id, _label in tqdm(tf.entity_id_to_label.items()):\n",
    "    text  = sr_description.loc[_label]\n",
    "    numeric_literals[_id, :] = nlp(text).vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1539db6f-75c6-444e-8eb7-7e040c37d5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "tlf = TriplesNumericLiteralsFactory(mapped_triples = tf.mapped_triples, \n",
    "                                    entity_to_id = tf.entity_to_id, \n",
    "                                    relation_to_id = tf.relation_to_id,\n",
    "                                    numeric_literals=numeric_literals,\n",
    "                                    literals_to_id=tf.entity_to_id\n",
    "                                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e0e57ec-580d-4709-9453-616f3382cddd",
   "metadata": {},
   "source": [
    "## 4. Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ff6cfc3-194a-471d-a849-f68825eada8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Wikidata5M'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db = DataBinder(target_dir=dir_save)\n",
    "db.add('tf', tf)\n",
    "db.add('tlf', tlf)\n",
    "db.add('sampling_ratio', sampling_ratio)\n",
    "db.add('embedding model', name_nlp)\n",
    "db.add('knowledge_graph_name', name_kg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1583dc5d-5aaf-4a2e-9ee4-5c54f6592ca2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
