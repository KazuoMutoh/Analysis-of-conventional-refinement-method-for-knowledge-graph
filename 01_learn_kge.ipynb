{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f762b0e6-3c57-458c-bdbe-22ce57a7d423",
   "metadata": {},
   "source": [
    "# Knowledge Embedding with Pykeen\n",
    "## 概要\n",
    "- 知識グラフから知識グラフの埋め込みモデルを学習する．\n",
    "- pykeenにあらかじめ入っているデータセットに関しては，この[GitHub](https://github.com/pykeen/benchmarking)のページを参考にハイパーパラメータを設定．\n",
    "## 入力データ・パラメータ\n",
    "- 知識グラフ埋め込みモデル名\n",
    "- 知識グラフ\n",
    "- ランダムシード（optional）\n",
    "## 出力データ\n",
    "- 各ランダムシードの知識グラフ\n",
    "- メタデータ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead0b966-8f00-44c6-a5fc-7dc0736aa9d1",
   "metadata": {},
   "source": [
    "## modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8bed98b-6697-47ec-b585-df176ca1fac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/42827306.1.gpu/ipykernel_3127177/452844227.py:8: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import os\n",
    "import logging\n",
    "import shutil\n",
    "import multiprocessing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.autonotebook import tqdm\n",
    "from pykeen.pipeline import pipeline\n",
    "from pykeen.datasets import get_dataset\n",
    "\n",
    "from util.databinder import DataBinder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33574698-18fe-4688-8802-89ba9edf1fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.DEBUG,\n",
    "                    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "                    datefmt='%Y-%m-%d %H:%M:%S')\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ea47e8-fd16-4b11-a0f4-702d1438f298",
   "metadata": {},
   "source": [
    "## functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b8b8dd9-933d-41d6-b95f-fe3cac67e615",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_dtype(value):\n",
    "    if isinstance(value, np.floating):\n",
    "        return float(value)\n",
    "    elif isinstance(value, np.integer):\n",
    "        return int(value)\n",
    "    else:\n",
    "        return value\n",
    "\n",
    "def delete_all_files_in_directory(directory):\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            file_path = os.path.join(root, file)\n",
    "            os.remove(file_path)\n",
    "        for dir in dirs:\n",
    "            dir_path = os.path.join(root, dir)\n",
    "            shutil.rmtree(dir_path)\n",
    "\n",
    "def get_best_params(f_params:str, model_name:str, dataset_name:str):\n",
    "    \"\"\"\n",
    "    最適なハイパーパラメータを取得する．\n",
    "    TODO:\n",
    "        洗練されていないので修正すること．\n",
    "    \"\"\"\n",
    "    df_best_params = pd.read_pickle(f_params).reset_index()\n",
    "    df_best_params = df_best_params[df_best_params['model'].isin([model_name])]\n",
    "    df_best_params = df_best_params[df_best_params['dataset'].isin([dataset_name])]\n",
    "    \n",
    "    dict_args = {}\n",
    "    idx = 0\n",
    "    \n",
    "    dict_args['dataset'] = df_best_params.loc[idx,'dataset']\n",
    "    \n",
    "    dict_args['dataset_kwargs'] = {}\n",
    "    for k, v in df_best_params.filter(regex='pipeline_config.pipeline.dataset_kwargs').loc[idx].items():\n",
    "        if not np.isnan(v):\n",
    "            dict_args['dataset_kwargs'][k.split('.')[-1]] = v\n",
    "\n",
    "    dict_args['evaluator'] = df_best_params.loc[idx,'evaluator']\n",
    "\n",
    "    dict_args['evaluator_kwargs'] = {}\n",
    "    for k, v in df_best_params.filter(regex='pipeline_config.pipeline.evaluator_kwargs').loc[idx].items():\n",
    "        if not np.isnan(v):\n",
    "            dict_args['evaluator_kwargs'][k.split('.')[-1]] = v\n",
    "    \n",
    "    dict_args['model'] = df_best_params.loc[idx,'model']\n",
    "\n",
    "    dict_args['loss'] = df_best_params.loc[idx, 'loss']\n",
    "\n",
    "    dict_args['regularizer'] = df_best_params.loc[idx, 'regularizer']\n",
    "\n",
    "    dict_args['optimizer'] = df_best_params.loc[idx, 'optimizer']\n",
    "\n",
    "    dict_args['optimizer_kwargs'] = {}\n",
    "    for k, v in df_best_params.filter(regex='pipeline_config.pipeline.optimizer_kwargs').loc[idx].items():\n",
    "        if not np.isnan(v) and 'automatic_memory_optimization' not in k:\n",
    "            dict_args['optimizer_kwargs'][k.split('.')[-1]] = convert_dtype(v)\n",
    "    \n",
    "    dict_args['model_kwargs'] = {}\n",
    "    for k, v in df_best_params.filter(regex='pipeline_config.pipeline.model_kwargs').loc[idx].items():\n",
    "        if not np.isnan(v) and 'automatic_memory_optimization' not in k:\n",
    "            k = k.split('.')[-1]\n",
    "            if k in ['output_channels', 'kernel_height', 'kernel_width']:\n",
    "                v = int(v)    \n",
    "            dict_args['model_kwargs'][k] = convert_dtype(v)\n",
    "\n",
    "    dict_args['training_loop'] = df_best_params.loc[idx, 'training_loop']\n",
    "\n",
    "    dict_args['training_kwargs'] = {}\n",
    "    for k, v in df_best_params.filter(regex='pipeline_config.pipeline.training_kwargs').loc[idx].items():\n",
    "        if not np.isnan(v):\n",
    "            k = k.split('.')[-1]\n",
    "            if k in ['batch_size', 'num_epochs']:\n",
    "                v = int(v)\n",
    "\n",
    "            #if k not in ['label_smoothing']:\n",
    "            #    dict_args['training_kwargs'][k.split('.')[-1]] = v\n",
    "            dict_args['training_kwargs'][k.split('.')[-1]] = v\n",
    "\n",
    "    return dict_args\n",
    "\n",
    "\n",
    "def learn_embedding(dict_args:dict, dir_save:str=None):\n",
    "    \"\"\"\n",
    "    知識グラフ埋込モデルを計算する.\n",
    "    \n",
    "    Args:\n",
    "        dict_args(dict):\n",
    "            埋め込みモデル学習のためのパラメータ．\n",
    "            デフォルトのパラメータを使う場合でも，\n",
    "            datasetとmodelのキーワードは必須\n",
    "        dir_save(str):\n",
    "            None以外の時は指定されたディレクトリに学習結果を\n",
    "            保存する．\n",
    "    Returns:\n",
    "        pipeline_result:\n",
    "            pykeenのpipelineのresult\n",
    "            [PipelineResult](https://pykeen.readthedocs.io/en/stable/api/pykeen.pipeline.PipelineResult.html)\n",
    "    \"\"\"\n",
    "    \n",
    "    logger.info(f'start learning embedding in random seed {dict_args.get(\"random_seed\")}')  \n",
    "    \n",
    "    pipeline_result = pipeline(**dict_args)\n",
    "\n",
    "    hits_at_10 = pipeline_result.get_metric('hits_at_10')\n",
    "    print('Hits@10\\t' + str(hits_at_10))\n",
    "\n",
    "    if dir_save != None:\n",
    "        pipeline_result.save_to_directory(dir_save)\n",
    "\n",
    "    logger.info(f'finish learning embedding in random seed {dict_args.get(\"random_seed\")}') \n",
    "        \n",
    "    return pipeline_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569a963e-a147-4d0c-8394-4ee2e4b7af4c",
   "metadata": {},
   "source": [
    "## parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81711383-cf79-456a-b213-bd6c4c7e60fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for input\n",
    "# ----------------------------------------------------\n",
    "## a path to the data fra\n",
    "f_params = '../benchmarking/df_best_param.pkl'\n",
    "## a name of knowledge graph embedding model\n",
    "model_name = 'transe'\n",
    "## a data set (knowledge graph)\n",
    "dataset_name = 'fb15k237'\n",
    "## a list of random seeds which should be unique for each other\n",
    "list_random_seeds = [0, 1]\n",
    "## a number of epochs (if None, using best value)\n",
    "num_epochs = 1\n",
    "##  a maiximum number of multi processing\n",
    "num_process = 1\n",
    "\n",
    "# for output\n",
    "# ----------------------------------------------------\n",
    "## a direcory where learned model are saved\n",
    "del_previous_result = True\n",
    "output_name = 'try2'\n",
    "dir_learned_model = f'./models/20240811/kge_{output_name}_{model_name}_{dataset_name}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065291f9-ba4d-4e9d-8afc-b735acdc36ab",
   "metadata": {},
   "source": [
    "## preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b107f54a-ab62-4ef1-8da3-e169e8813e6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Create ./models/20240811/kge_try2_transe_fb15k237/info.json\n",
      "WARNING:root:./models/20240811/kge_try2_transe_fb15k237 may not be for Data Binder.\n"
     ]
    }
   ],
   "source": [
    "if del_previous_result:\n",
    "    delete_all_files_in_directory(dir_learned_model)\n",
    "if not os.path.exists(dir_learned_model):\n",
    "    os.mkdir(dir_learned_model)\n",
    "db = DataBinder(dir_learned_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb8c528-fd08-40ae-acba-adc8404de2c4",
   "metadata": {},
   "source": [
    "## main"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3a86ea-dbf5-4e8d-9348-326dd050da75",
   "metadata": {},
   "source": [
    "### create args."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3545dd50-c978-4615-b853-b84d25c2ecc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_base_args = get_best_params(f_params, model_name, dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f44c1df-cda3-47e0-a343-12b8e8d495dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "if num_epochs != None:\n",
    "    dict_base_args['training_kwargs']['num_epochs'] = num_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c404c45-5c10-463e-8232-097059c96944",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataset': 'fb15k237',\n",
       " 'dataset_kwargs': {'create_inverse_triples': True},\n",
       " 'evaluator': 'rankbased',\n",
       " 'evaluator_kwargs': {'filtered': True},\n",
       " 'model': 'transe',\n",
       " 'loss': 'crossentropy',\n",
       " 'regularizer': 'no',\n",
       " 'optimizer': 'adam',\n",
       " 'optimizer_kwargs': {'lr': 0.0016608460884079, 'weight_decay': 0.0},\n",
       " 'model_kwargs': {'embedding_dim': 64, 'scoring_fct_norm': 1.0},\n",
       " 'training_loop': 'lcwa',\n",
       " 'training_kwargs': {'batch_size': 256,\n",
       "  'label_smoothing': 0.717650072390557,\n",
       "  'num_epochs': 1}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_base_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1113b9c7-523d-423b-8eac-826e0a508a95",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "f-string: expecting '}' (1173603793.py, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[9], line 5\u001b[0;36m\u001b[0m\n\u001b[0;31m    list_args.append((dict_args,f'{dir_learned_model}/{random_seed/result'))\u001b[0m\n\u001b[0m                                                                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m f-string: expecting '}'\n"
     ]
    }
   ],
   "source": [
    "list_args= []\n",
    "for random_seed in list_random_seeds:\n",
    "    dict_args = copy.deepcopy(dict_base_args)\n",
    "    dict_args['random_seed'] = random_seed\n",
    "    list_args.append((dict_args,f'{dir_learned_model}/{random_seed/result'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71705134-fcd1-4d0b-886e-3977021a0885",
   "metadata": {},
   "outputs": [],
   "source": [
    "for random_seed, (dict_args, dir_save) in zip(list_random_seeds, list_args):\n",
    "    result = learn_embedding(dict_args, dir_save)\n",
    "    db.add(f'model_{random_seed}', result.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc26229-a70d-4122-b4a9-ccf9a4668d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "db.add('model_name', model_name)\n",
    "db.add('dataset_name', dataset_name)\n",
    "db.add('dict_args', dict_args)\n",
    "db.add('f_params', f_params)\n",
    "db.add('list_random_seeds', list_random_seeds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
