{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8026f2f-b407-4280-95f0-e909a94cf6f5",
   "metadata": {},
   "source": [
    "# Create Knowledge Graph and Its Features Table for Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb33c186-0a5a-4fcf-9674-e84866b4c2a0",
   "metadata": {},
   "source": [
    "## modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a5c27dd-7e3f-4e21-a610-0f579b375f36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/acg16558pn/kg_20240423/lib/python3.10/site-packages/pykeen/evaluation/evaluator.py:16: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "import json\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from pykeen.pipeline import pipeline\n",
    "from pykeen.datasets import get_dataset\n",
    "from pykeen.models import TransE, ComplEx, ConvE\n",
    "from pykeen.losses import Loss\n",
    "from pykeen.models.base import Model\n",
    "from pykeen.triples import TriplesFactory\n",
    "\n",
    "from util.databinder import DataBinder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de99fe1a-00a0-4b18-a2e1-ba181140fd01",
   "metadata": {},
   "source": [
    "## variable, functions, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d93d3b51-eafb-4c6a-9a7d-cf91b60f1428",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_false_triples(tf:TriplesFactory, ratio:float=0.1, random_seed:int=0) -> TriplesFactory:\n",
    "\n",
    "    # fix random seed\n",
    "    np.random.seed(random_seed)\n",
    "    \n",
    "    num_false = int(tf.num_triples * ratio)\n",
    "    false_triples = tf.mapped_triples.clone()\n",
    "    false_indices = np.random.choice(tf.num_triples, num_false)\n",
    "    for i in false_indices:\n",
    "        if np.random.random() < 0.5:  # Replace head\n",
    "            false_triples[i, 0] = np.random.choice(tf.num_entities)\n",
    "        else:  # Replace tail\n",
    "            false_triples[i, 2] = np.random.choice(tf.num_entities)\n",
    "    return TriplesFactory(false_triples, tf.entity_to_id, tf.relation_to_id, create_inverse_triples=tf.create_inverse_triples), false_indices\n",
    "\n",
    "def create_triples_feature_table(tf:TriplesFactory) -> pd.DataFrame:\n",
    "    \n",
    "    triples = tf.mapped_triples.numpy()\n",
    "    head_labels = [tf.entity_id_to_label[h] for h in triples[:, 0]]\n",
    "    relation_labels = [tf.relation_id_to_label[r] for r in triples[:, 1]]\n",
    "    tail_labels = [tf.entity_id_to_label[t] for t in triples[:, 2]]\n",
    "    \n",
    "    # Calculate degrees\n",
    "    head_degrees = np.array([np.sum(triples[:, 0] == h) for h in triples[:, 0]])\n",
    "    tail_degrees = np.array([np.sum(triples[:, 2] == t) for t in triples[:, 2]])\n",
    "    \n",
    "    return pd.DataFrame({\n",
    "        'head': head_labels,\n",
    "        'relation': relation_labels,\n",
    "        'tail': tail_labels,\n",
    "        'head_degree': head_degrees,\n",
    "        'tail_degree': tail_degrees,\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a8059d-a7bd-4f08-813e-a0244552ca5b",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2daca6f1-c1cb-46b8-9cdb-77e899ba50be",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_model = './models/20240628_distmultliteral'\n",
    "false_ratio = 0.1\n",
    "list_random_seed = [1,2,3,4,5,6,7,8,9,10]\n",
    "dir_save = './data/processed/20240628_false_fb15k237_with_lit'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573d85cd-99fb-4296-9d76-eda7df4c2e4f",
   "metadata": {},
   "source": [
    "## 1. Load knowledge graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11049d7b-d0d3-4939-8ca4-54ba3c0cc814",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Loaded info from ./models/20240628_distmultliteral/info.json\n"
     ]
    }
   ],
   "source": [
    "db_model = DataBinder(target_dir=dir_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee21e272-d159-4bbb-be87-dc13df92a5f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pykeen.datasets.utils:Loading cached preprocessed dataset from file:///home/acg16558pn/.data/pykeen/datasets/kinships/cache/47DEQpj8HBSa-_TImW-5JCeuQeRkm5NM\n",
      "INFO:pykeen.triples.triples_factory:Loading from file:///home/acg16558pn/.data/pykeen/datasets/kinships/cache/47DEQpj8HBSa-_TImW-5JCeuQeRkm5NM/training\n",
      "INFO:pykeen.triples.triples_factory:Loading from file:///home/acg16558pn/.data/pykeen/datasets/kinships/cache/47DEQpj8HBSa-_TImW-5JCeuQeRkm5NM/testing\n",
      "INFO:pykeen.triples.triples_factory:Loading from file:///home/acg16558pn/.data/pykeen/datasets/kinships/cache/47DEQpj8HBSa-_TImW-5JCeuQeRkm5NM/validation\n"
     ]
    }
   ],
   "source": [
    "dataset = get_dataset(dataset=name_kg,dataset_kwargs={'create_inverse_triples':True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04a00d1d-bf0e-4c97-bfce-68ec066513c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EagerDataset (create_inverse_triples=True)\n",
      "Name        Entities    Relations      Triples\n",
      "----------  ----------  -----------  ---------\n",
      "Training    104         50                8544\n",
      "Testing     104         25                1074\n",
      "Validation  104         25                1068\n",
      "Total       -           -                10686\n",
      "Head     Relation    tail\n",
      "-------  ----------  --------\n",
      "person0  term0       person45\n",
      "person0  term10      person51\n",
      "person0  term10      person52\n",
      "person0  term10      person57\n",
      "person0  term10      person58\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset.summarize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f1fbfc-6bb7-4a9c-8eb2-2101d20ba5e4",
   "metadata": {},
   "source": [
    "## 2. Create false triple and its feature table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6807f1fa-b958-4056-b68e-0877c68d3fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf_tt = dataset.testing\n",
    "tf_tt = dataset.training\n",
    "df_tt_features = create_triples_feature_table(tf_tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb079830-55b9-45e2-b603-cee3a9e9c9bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 10/10 [00:02<00:00,  3.99it/s]\n"
     ]
    }
   ],
   "source": [
    "dict_data = {}\n",
    "for random_seed in tqdm(list_random_seed):\n",
    "    \n",
    "    tf_tf, false_indices = create_false_triples(tf_tt, ratio=false_ratio, random_seed=random_seed)\n",
    "    \n",
    "    df_tf_features = create_triples_feature_table(tf_tf)\n",
    "    \n",
    "    df1 = df_tt_features.copy(deep=True)\n",
    "    df1.rename(columns={\n",
    "        'head':'head(org)',\n",
    "        'relation':'relation(org)',\n",
    "        'tail':'tail(org)',\n",
    "        'head_degree':'head_degree(org)',\n",
    "        'tail_degree':'tail_degree(org)'},\n",
    "        inplace=True)\n",
    "    df2 = df_tf_features.copy(deep=True)\n",
    "    df_tt_tf_features = pd.concat([df1, df2], axis=1)\n",
    "    df_tt_tf_features['is-error'] = [(True) if (idx in false_indices) else (False) for idx in df_tt_tf_features.index]\n",
    "    df_tt_tf_features['degree'] = df_tt_tf_features['head_degree'] + df_tt_tf_features['tail_degree']\n",
    "\n",
    "    dict_data[random_seed] = {}\n",
    "    dict_data[random_seed]['tf'] = tf_tf\n",
    "    dict_data[random_seed]['df_feature'] = df_tt_tf_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e0e57ec-580d-4709-9453-616f3382cddd",
   "metadata": {},
   "source": [
    "## 3. Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a21cc8c3-1596-4b19-b690-2d00cf828b16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Create ./data/processed/20240622_false_kinships_based_on_training_data\n",
      "INFO:root:Saved info at 2024-06-22 07:28:31\n",
      "INFO:root:Saved info at 2024-06-22 07:28:31\n",
      "INFO:root:Saved info at 2024-06-22 07:28:31\n",
      "INFO:root:Saved info at 2024-06-22 07:28:31\n",
      "INFO:root:Saved info at 2024-06-22 07:28:31\n",
      "INFO:root:Saved info at 2024-06-22 07:28:31\n",
      "INFO:root:Saved info at 2024-06-22 07:28:31\n",
      "INFO:root:Saved info at 2024-06-22 07:28:31\n",
      "INFO:root:Saved info at 2024-06-22 07:28:31\n",
      "INFO:root:Saved info at 2024-06-22 07:28:31\n",
      "INFO:root:Saved info at 2024-06-22 07:28:31\n",
      "INFO:root:Saved info at 2024-06-22 07:28:31\n",
      "INFO:root:Saved info at 2024-06-22 07:28:31\n",
      "INFO:root:Saved info at 2024-06-22 07:28:31\n",
      "INFO:root:Saved info at 2024-06-22 07:28:31\n",
      "INFO:root:Saved info at 2024-06-22 07:28:31\n",
      "INFO:root:Saved info at 2024-06-22 07:28:31\n",
      "INFO:root:Saved info at 2024-06-22 07:28:31\n",
      "INFO:root:Saved info at 2024-06-22 07:28:31\n",
      "INFO:root:Saved info at 2024-06-22 07:28:31\n",
      "INFO:root:Saved info at 2024-06-22 07:28:31\n",
      "INFO:root:Saved info at 2024-06-22 07:28:31\n",
      "INFO:root:Saved info at 2024-06-22 07:28:31\n"
     ]
    }
   ],
   "source": [
    "db = DataBinder(target_dir=dir_save)\n",
    "db.add('false_ratio', false_ratio)\n",
    "db.add('list_random_seed', list_random_seed)\n",
    "db.add('name_kg', name_kg)\n",
    "for random_seed in dict_data.keys():\n",
    "    db.add(f'tf_{random_seed}', dict_data[random_seed]['tf'])\n",
    "    db.add(f'df_tt_tf_features_{random_seed}', dict_data[random_seed]['df_feature'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf736b84-dcf3-4a0c-8d4e-31f17806409c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
